{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running GWAS using limix\n",
    "We're going to run GWAS using the limix library for python.\n",
    "Limix is freely available [here](https://github.com/limix/limix) and has an extensive [documentation](https://limix.readthedocs.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  Initial setup steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a. Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "from limix.qtl import scan\n",
    "from bisect import bisect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phenotype file\n",
    "pheno_file = './data/subset_flowering_time_16.csv'\n",
    "# genotypes file\n",
    "geno_file = './data/subset_all_chromosomes_binary.hdf5'\n",
    "# kinship matrix file\n",
    "kin_file = './data/kinship_ibs_binary_mac5.h5py'\n",
    "# minor allele frequency threshold\n",
    "MAF_thrs = 0.1\n",
    "# output file for results with K correction\n",
    "output_file = './results/subset_flowering_time_16.csv'\n",
    "# output file for results without K correction\n",
    "output_file_nc = './results/subset_flowering_time_16_nc.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load input for GWAS\n",
    "We need three variables to run GWAS:\n",
    "1.  Phenotype matrix (Y)\n",
    "2.  Genotype matrix (G)\n",
    "3.  K matrix (K)\n",
    "\n",
    "The first step to generating these variables is to load the data.\n",
    "\n",
    "### Please Note!\n",
    "This script is written to handle data from the *Arabidopsis thaliana* 1001 genome project.  If you are running GWAS using another organism, you will more than likely start with data that is formatted differently!  If this is the case, some parts of this code *will not* work for you out of the box.  However, if you understand the __steps__ that this code takes, you will be able to adapt it to suit your specific input data.\n",
    "\n",
    "Therefore, I would like you to __focus on the general approach__ to generating the Y, G, and K matrices rather than trying to understand every line of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Load phenotypes\n",
    "The phenotype data are stored in a 2-column .csv file.\n",
    "The first column specifies the accession identifier (\"ecotypeid\"), the second column contains the phenotype value.  Our flowering time dataset has 200 accessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load phenotype data\n",
    "pheno = pd.read_csv(pheno_file, index_col = 0)\n",
    "\n",
    "# encode the index (the accessions column) to UTF8 for compatability with the genotype data\n",
    "pheno.index = pheno.index.map(lambda x: str(int(x)).encode('UTF8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove accessions with missing or non numerical\n",
    "#pheno = pheno[np.isfinite(pheno)]\n",
    "pheno = pheno.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does pheno match our expectations?\n",
    "print(pheno.shape)\n",
    "print(pheno.head(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The phenotypes are loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. Load genotypes\n",
    "The genotypes we're going to use are a subset of SNPs obtained from whole-genome resequencing of 1,135 *Arabidopsis thaliana* accessions ([1001 genomes](http://1001genomes.org/)).\n",
    "\n",
    "Genotype data is stored as an [hdf5](https://www.h5py.org/) file, which is a composite data type.  This means that one hdf5 file stores multiple related data sets. \n",
    "\n",
    "The genotype hdf5 file we are using here consists of three data sets:\n",
    "1.  'accessions' contains the accession identifiers.\n",
    "2.  'positions' provides the SNP positions.\n",
    "3.  'snps' gives the SNP calls themselves. SNPs are coded as 0 for reference allele and 1 for alternate allele.\n",
    "\n",
    "The 'positions' dataset is also associated with a small file called an attribute which provides information about the chromosome location ('chr_index').  We will use the attribute later when outputting GWAS results.\n",
    "\n",
    "(If you are interested in learning more about how to use hdf5 files, check out https://www.pythonforthelab.com/blog/how-to-use-hdf5-files-in-python/ after class for a more detailed introduction.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load genotype data\n",
    "geno_hdf = h5py.File(geno_file, 'r')\n",
    "# structure of hdf5 file\n",
    "# does geno_hdf match our expectations? Here, \"key\" refers to the three different data sets\n",
    "for key in geno_hdf.keys():\n",
    "    print(key)\n",
    "    print(geno_hdf[key].shape)\n",
    "    print(geno_hdf[key][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2c.  Load K matrix\n",
    "This hdf5 file is also an hdf5 file.  It contains 2 datasets:\n",
    "1. 'accessions' gives the accession identifiers\n",
    "2. 'kinship' is the kinship matrix.  (In this case, it is calculated for all 1135 accessions in the complete 1001 genomes dataset.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kin_hdf = h5py.File(kin_file, 'r')\n",
    "\n",
    "print(kin_hdf['accessions'].shape)\n",
    "print(kin_hdf['accessions'][0:5])\n",
    "print(kin_hdf['kinship'].shape)\n",
    "print(kin_hdf['kinship'][0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.  Generating matrices for GWAS\n",
    "Now that the data have been loaded, we need to do some final manipulations to generate the appropriate input matrices.  We have two main objectives here:\n",
    "\n",
    "1.  Since limix will not work with missing data, we need to make sure that all three matrices include the __same set of accessions__.\n",
    "2.  We also need to make sure that the accessions appear in the __same order__ in all three matrices.\n",
    "\n",
    "We will also remove any SNPs that don't meet our minor allele frequency threshold.\n",
    "\n",
    "Again, this code will work for the 1001 genomes data out of the box, but will likely need to be modified for other data.  Therefore, focus on the __steps__ rather than on each individual line of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a.  Generate phenotype matrix (Y)\n",
    "\n",
    "We now have the phenotypes stored as the variable called 'pheno'.  To finish the phenotype matrix (Y), we need to __*remove non-genotyped accessions*__ and __*order the data*__ to match the genotype data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-genotyped accessions from phenotype\n",
    "acn_genotyped = [acn for acn in pheno.index if acn in geno_hdf['accessions'][:]]\n",
    "# subset phenotype data\n",
    "pheno = pheno.loc[acn_genotyped]\n",
    "# order genotypes in phenotype according SNP-matrix\n",
    "acn_indices = [np.where(geno_hdf['accessions'][:] == acn)[0][0] for acn in pheno.index]\n",
    "acn_indices.sort()\n",
    "acn_order = geno_hdf['accessions'][acn_indices]\n",
    "pheno = pheno.loc[acn_order]\n",
    "# transform to a numpy phenotype matrix (Y)\n",
    "Y = pheno.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The phenotype matrix (Y) is now ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. Finish genotype matrix (G)\n",
    "Now we can finish the genotype matrix (G).  Here we remove:\n",
    "1. accessions that are not genotyped \n",
    "2. SNPs with a minor allele frequency below our threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset SNP matrix for phenotyped genotypes\n",
    "G = geno_hdf['snps'][:, acn_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove SNPs with minor allele frequency below set threshold\n",
    "# count allele 1 and 0 for each SNP\n",
    "AC1 = G.sum(axis = 1)\n",
    "AC0 = G.shape[1] - AC1\n",
    "AC = np.vstack((AC0,AC1))\n",
    "# define the minor allele for each position\n",
    "MAC = np.min(AC, axis = 0)\n",
    "# calculate minor allele frequency\n",
    "MAF = MAC/G.shape[1]\n",
    "# select SNPs with MAF above threshold \n",
    "SNP_indices = np.where(MAF >= MAF_thrs)[0]\n",
    "SNPs_MAF = MAF[SNP_indices]\n",
    "G = G[SNP_indices, :]\n",
    "\n",
    "# transpose SNP-matrix into accessions x SNPs matrix\n",
    "G = G.transpose()\n",
    "geno_hdf.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The genotype matrix (G) is now ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c. Finish kinship matrix (K)\n",
    "To finish the kinship array, subset for accessions that are phenotyped and genotyped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset kinship matrix for phenotyped and genotyped accessions\n",
    "acn_indices = [np.where(kin_hdf['accessions'][:] == acn)[0][0] for acn in pheno.index]\n",
    "acn_indices.sort()\n",
    "K = kin_hdf['kinship'][acn_indices, :][:, acn_indices]\n",
    "kin_hdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kinship matrix (K) is now ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Running GWAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4a.  Check input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all three of our input variables.  If you are running GWAS using something other than the 1001 genomes data, __these are the matrices that you need to generate to run limix__.  Let's quickly look at these variables to make sure we understand their format.  The number of accessions should be the same in all three matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y matrix (phenotypes)\n",
    "*Y is a numpy array.\n",
    "The number of rows = number of accessions.\n",
    "The number of columns = 1.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(type(Y))\n",
    "print(Y.shape)\n",
    "print(Y[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G matrix (genotypes)\n",
    "*G is a numpy array.  The number of rows = number of accessions.  The number of columns = the number of snps.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(type(G))\n",
    "print(G.shape)\n",
    "print(G[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K matrix (K matrix)\n",
    "*K is a numpy array.  The number of rows and columns = the number of accessions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(type(K))\n",
    "print(K.shape)\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b.  Run limix with K correction\n",
    "\n",
    "Now that we have phenotype (Y), genotype (G), and K (K) matrices, we can run GWAS using the 'scan' function from limix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = scan(G, Y, K = K, lik = 'normal', M = None, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4c.  Output results for limix with K correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This saves the GWAS results as a .csv file that gives chromosome (chr), position (pos), p-value (pvalue), minor allele frequency (maf), and effect size (GVE) for each SNP.  We will explore this output in the next jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "\n",
    "# get chromosomes, positions, and minor allele frequencies\n",
    "# you would need to recode this section if working with something other than the 1001 genomes data\n",
    "geno_hdf = h5py.File(geno_file, 'r')\n",
    "chr_index = geno_hdf['positions'].attrs['chr_regions']\n",
    "chromosomes = [bisect(chr_index[:, 1], snp_index) + 1 for snp_index in SNP_indices]\n",
    "positions_all = geno_hdf['positions'][:]\n",
    "positions = [positions_all[snp] for snp in SNP_indices]\n",
    "mafs = SNPs_MAF #from section 3b\n",
    "\n",
    "# get p-value and effect size\n",
    "# these variables are output from limix and should work regardless of initial input data format\n",
    "#extract p-values\n",
    "pvalues = r.stats.pv20.tolist()\n",
    "#extract effect sizes\n",
    "effsizes = r.effsizes['h2']['effsize'][r.effsizes['h2']['effect_type'] == 'candidate'].tolist()\n",
    "\n",
    "gwas_results = pd.DataFrame(list(zip(chromosomes, positions, pvalues, mafs,effsizes)), columns = ['chr', 'pos', 'pvalue', 'maf', 'GVE'])\n",
    "gwas_results.to_csv(output_file, index = False)\n",
    "geno_hdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4d.  Run limix without K correction\n",
    "\n",
    "For comparison, we will also run limix without K in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r_nc = scan(G, Y, lik=\"normal\", M=None, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4e.  Output results for limix without K correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "# link chromosome and position to p-values and effect sizes\n",
    "geno_hdf = h5py.File(geno_file, 'r')\n",
    "chr_index = geno_hdf['positions'].attrs['chr_regions']\n",
    "chromosomes = [bisect(chr_index[:, 1], snp_index) + 1 for snp_index in SNP_indices]\n",
    "positions_all = geno_hdf['positions'][:]\n",
    "positions = [positions_all[snp] for snp in SNP_indices]\n",
    "mafs = SNPs_MAF #from section 3b\n",
    "\n",
    "pvalues = r_nc.stats.pv20.tolist()\n",
    "effsizes = r_nc.effsizes['h2']['effsize'][r_nc.effsizes['h2']['effect_type'] == 'candidate'].tolist()\n",
    "\n",
    "gwas_results = pd.DataFrame(list(zip(chromosomes, positions, pvalues, mafs, effsizes)), columns = ['chr', 'pos', 'pvalue', 'maf', 'GVE'])\n",
    "gwas_results.to_csv(output_file_nc, index = False)\n",
    "geno_hdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### We have learned about input data and run GWAS.\n",
    " ### Let's move on to 3_GWAS_interpretation.ipynb where we will explore our GWAS results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
